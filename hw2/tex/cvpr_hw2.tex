\documentclass[12pt, a4paper, oneside]{ctexart}
\usepackage{amsmath, amsthm, amssymb, bm, color, graphicx, geometry, mathrsfs,extarrows, braket, booktabs, array, xcolor, fontspec, appendix, float, subfigure, wrapfig, enumitem, titlesec}
\usepackage{tikz}
\usepackage{tabularx}
\usetikzlibrary{positioning}
\usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=blue,urlcolor=blue,menucolor=black]{hyperref}

%%%% 设置中文字体 %%%%
% fc-list -f "%{family}\n" :lang=zh >d:zhfont.txt 命令查看已有字体
\setCJKmainfont[
    BoldFont=方正黑体_GBK,  % 黑体
    ItalicFont=方正楷体_GBK,  % 楷体
    BoldItalicFont=方正粗楷简体,  % 粗楷体
    Mapping = fullwidth-stop  % 将中文句号“.”全部转化为英文句号“.”,
]{方正书宋简体}  % !!! 注意在Windows中运行请改为“方正书宋简体.ttf” !!!
%%%% 设置英文字体 %%%%
\setmainfont{Minion Pro}
\setsansfont{Calibri}
\setmonofont{Consolas}

%%%% 设置代码块 %%%%
% 在vscode中使用minted需要先配置python解释器, Ctrl+Shift+P, 输入Python: Select Interpreter选择安装了Pygments的Python版本. 再在setting.json中xelatex和pdflatex的参数中加入 "--shell-escape", 即可
% TeXworks中配置方法参考: https://blog.csdn.net/RobertChenGuangzhi/article/details/108140093
\usepackage{minted}
\renewcommand{\theFancyVerbLine}{
    \sffamily\textcolor[rgb]{0.5,0.5,0.5}{\scriptsize\arabic{FancyVerbLine}}} % 修改代码前序号大小
% 加入不同语言的代码块
\newmintinline{cpp}{fontsize=\small, linenos, breaklines, frame=lines}
\newminted{cpp}{fontsize=\small, baselinestretch=1, linenos, breaklines, frame=lines}
\newmintedfile{cpp}{fontsize=\small, baselinestretch=1, linenos, breaklines, frame=lines}
\newmintinline{matlab}{fontsize=\small, linenos, breaklines, frame=lines}
\newminted{matlab}{fontsize=\small, baselinestretch=1, mathescape, linenos, breaklines, frame=lines}
\newmintedfile{matlab}{fontsize=\small, baselinestretch=1, linenos, breaklines, frame=lines}
\newmintinline{python}{fontsize=\small, linenos, breaklines, frame=lines, python3}  % 使用\pythoninline{代码}
\newminted{python}{fontsize=\small, baselinestretch=1, linenos, breaklines, frame=lines, python3}  % 使用\begin{pythoncode}代码\end{pythoncode}
\newmintedfile{python}{fontsize=\small, baselinestretch=1, linenos, breaklines, frame=lines, python3}  % 使用\pythonfile{代码地址}

%%%% 设置行间距与页边距 %%%%
\linespread{1.2}
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}
% \geometry{left=1.84cm,right=1.84cm,top=2.18cm,bottom=2.18cm}  % 更小的页边距

%%%% 定理类环境的定义 %%%%
\newtheorem{example}{例}            % 整体编号
\newtheorem{theorem}{定理}[section] % 定理按section编号
\newtheorem{definition}{定义}
\newtheorem{axiom}{公理}
\newtheorem{property}{性质}
\newtheorem{proposition}{命题}
\newtheorem{lemma}{引理}
\newtheorem{corollary}{推论}
\newtheorem{condition}{条件}
\newtheorem{conclusion}{结论}
\newtheorem{assumption}{假设}
\numberwithin{equation}{section}  % 公式按section编号 (公式右端的小括号)
\newtheorem{algorithm}{算法}

%%%% 自定义环境 %%%%
\newsavebox{\nameinfo}
\newenvironment{myTitle}[1]{
    \begin{center}
    {\zihao{-2}\bf #1\\}
    \zihao{-4}\it
}{\end{center}}  % \begin{myTitle}{标题内容}作者信息\end{myTitle}
\newcounter{problem}  % 问题序号计数器
\newenvironment{problem}[1][]{\stepcounter{problem}\par\noindent\textbf{题目\arabic{problem}. #1}}{\smallskip\par}
\newenvironment{solution}[1][]{\par\noindent\textbf{#1解答. }}{\smallskip\par}  % 可带一个参数表示题号\begin{solution}{题号}
\newenvironment{note}{\par\noindent\textbf{注记. }}{\smallskip\par}
\newenvironment{remark}{\begin{enumerate}[label=\textbf{注\arabic*.}]}{\end{enumerate}}
\BeforeBeginEnvironment{minted}{\vspace{-0.5cm}}  % 缩小minted环境距上文间距
\AfterEndEnvironment{minted}{\vspace{-0.2cm}}  % 缩小minted环境距下文间距

%%%% 自定义段落开头序号，间距 (titlesec) %%%%
% 中文序号：\zhnum{section}, 阿拉伯序号：\arabic
\titleformat{\section}{\Large\bfseries}{\arabic{section}}{1em}{}[]
\titlespacing{\section}{0pt}{1.2ex plus .0ex minus .0ex}{.6ex plus .0ex}
\titlespacing{\subsection}{0pt}{1.2ex plus .0ex minus .0ex}{.6ex plus .0ex}
\titlespacing{\subsubsection}{0pt}{1.2ex plus .0ex minus .0ex}{.6ex plus .0ex}

%%%% 图片相对路径 %%%%
% \graphicspath{{figures/}} % 当前目录下的figures文件夹, {../figures/}则是父目录的figures文件夹
\setlength{\abovecaptionskip}{-0.2cm}  % 缩紧图片标题与图片之间的距离
\setlength{\belowcaptionskip}{0pt} 

%%%% 缩小item,enumerate,description两行间间距 %%%%
\setenumerate[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setitemize[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setdescription{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}

%%%% 自定义公式 %%%%
\everymath{\displaystyle} % 默认全部行间公式, 想要变回行内公式使用\textstyle
\DeclareMathOperator*\uplim{\overline{lim}}     % 定义上极限 \uplim_{}
\DeclareMathOperator*\lowlim{\underline{lim}}   % 定义下极限 \lowlim_{}
\DeclareMathOperator*{\argmax}{arg\,max}  % 定义取最大值的参数 \argmax_{}
\DeclareMathOperator*{\argmin}{arg\,min}  % 定义取最小值的参数 \argmin_{}
\let\leq=\leqslant % 简写小于等于\leq (将全部leq变为leqslant)
\let\geq=\geqslant % 简写大于等于\geq (将全部geq变为geqslant)
\DeclareRobustCommand{\rchi}{{\mathpalette\irchi\relax}}
\newcommand{\irchi}[2]{\raisebox{\depth}{$#1\chi$}} % 使用\rchi将\chi居中

%%%% 一些宏定义 %%%%
\def\bd{\boldsymbol}        % 加粗(向量) boldsymbol
\def\disp{\displaystyle}    % 使用行间公式 displaystyle(默认)
\def\tsty{\textstyle}       % 使用行内公式 textstyle
\def\sign{\text{sign}}      % sign function
\def\wtd{\widetilde}        % 宽波浪线 widetilde
\def\R{\mathbb{R}}          % Real number
\def\N{\mathbb{N}}          % Natural number
\def\Z{\mathbb{Z}}          % Integer number
\def\Q{\mathbb{Q}}          % Rational number
\def\C{\mathbb{C}}          % Complex number
\def\K{\mathbb{K}}          % Number Field
\def\P{\mathbb{P}}          % Polynomial
\def\E{\mathbb{E}}          % Exception
\def\d{\mathrm{d}}          % differential operator
\def\e{\mathrm{e}}          % Euler's number
\def\i{\mathrm{i}}          % imaginary number
\def\re{\mathrm{Re}}        % Real part
\def\im{\mathrm{Im}}        % Imaginary part
\def\res{\mathrm{Res}}      % Residue
\def\ker{\mathrm{Ker}}      % Kernel
\def\vspan{\mathrm{vspan}}  % Span  \span与latex内核代码冲突改为\vspan
\def\L{\mathcal{L}}         % Loss function
\def\O{\mathcal{O}}         % big O notation
\def\wdh{\widehat}          % 宽帽子 widehat
\def\ol{\overline}          % 上横线 overline
\def\ul{\underline}         % 下横线 underline
\def\add{\vspace{1ex}}      % 增加行间距
\def\del{\vspace{-1.5ex}}   % 减少行间距

%%%% 正文开始 %%%%
\begin{document}
%%%% 以下部分是正文 %%%%  
\clearpage
\begin{myTitle}{CVPR第二次作业\quad 图像分类实验}
    吴天阳\quad 4124136039\quad 人工智能学院B2480
\end{myTitle}
\section{实验目的}
\begin{enumerate}
    \item 基于两层神经网络的图像分类器；
    \item 学习使用PyTorch深度学习框架搭建图像分类器；
    \item 学习使用常用CNN结构和图像增强技术。
\end{enumerate}
\section{实验原理}
\subsection{全连接网络}

全连接网络用于图像分类的基本流程如下：

\subsubsection{输入图像}
给定一幅输入图像，假设大小为 $H \times W \times C$，其中：
\begin{itemize}
    \item $H$ 为图像高度（像素数）；
    \item $W$ 为图像宽度（像素数）；
    \item $C$ 为通道数（灰度图通道数为$1$，RGB图像通道数为$3$）。
\end{itemize}
将输入图像表示为一个张量 $x \in \mathbb{R}^{H \times W \times C}$。

\subsubsection{特征展平}
为了输入到全连接层，首先将图像展平成一个一维向量：
\[
x_{\text{flat}} = \text{flatten}(x) \in \mathbb{R}^{H W C}.
\]
此过程保留了图像的所有像素信息，但丢失了空间结构信息。

\subsubsection{全连接层计算}
全连接层通过一个权重矩阵 $W$ 和一个偏置向量 $\bd{b}$ 对输入进行线性变换：
\[
\bd{z} = W x_{\text{flat}} + \bd{b},
\]
其中：
\begin{itemize}
    \item $W \in \mathbb{R}^{N \times (H W C)}$ 是权重矩阵，$N$ 为神经元的数量。
    \item $b \in \mathbb{R}^{N}$ 是偏置向量。
    \item $z \in \mathbb{R}^N$ 是线性变换的结果。
\end{itemize}

\subsubsection{激活函数}
在线性变换之后，通过非线性激活函数（例如 ReLU）引入非线性特性：
\[
\bd{a} = \sigma(\bd{z}),
\]
其中 $\sigma$ 是激活函数，常用的包括：
\begin{itemize}
    \item ReLU: $\sigma(x) = \max(0, x)$\add
    \item Sigmoid: $\sigma(x) = \frac{1}{1 + e^{-x}}$\add
    \item Mish: $\sigma(x) = x\tanh(\text{softplus}(x))=x\tanh(\ln(1+e^x))$
\end{itemize}

\subsubsection{输出层和分类}
输出层通常是另一个全连接层，其输出的维度等于分类任务的类别数 $C_{\text{class}}$：
\[
\bd{y}_{\text{pred}} = \text{softmax}(W_{\text{out}} \bd{a} + \bd{b}_{\text{out}}),
\]
其中：
\begin{itemize}
    \item $W_{\text{out}} \in \mathbb{R}^{C_{\text{class}} \times N}$ 为输出层的权重。
    \item $\bd{b}_{\text{out}} \in \mathbb{R}^{C_{\text{class}}}$ 为输出层的偏置。
    \item $\text{softmax}$ 将输出变为概率分布：$\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}$。
\end{itemize}

\subsubsection{损失函数}
使用交叉熵损失函数（Cross-Entropy Loss）来衡量预测概率分布和真实标签的差异：
\[
\mathcal{L} = -\sum_{i=1}^{C_{\text{class}}} y_i \log(\hat{y}_i),
\]
其中：
\begin{itemize}
    \item $y_i$ 是真实标签的 one-hot 编码。
    \item $\hat{y}_i$ 是模型预测的概率分布。
\end{itemize}
通过梯度下降或其他优化方法更新网络参数，最小化损失函数。

\subsubsection{分类结果}
最终的分类结果为输出概率中最大值对应的类别：
\[
\text{class} = \arg\max_{i} \bd{y}_{\text{pred}}.
\]

\subsection{卷积网络}
一个典型的 CNN 模型包括以下几层：

\subsubsection{卷积层}
卷积层通过卷积核对输入数据进行操作，提取局部特征。卷积运算公式如下：
\[
z_{i,j}^k = \sum_{m=1}^{M} \sum_{n=1}^{N} x_{i+m-1,j+n-1} w_{m,n}^k + b^k,
\]
其中：
\begin{itemize}
    \item $x_{i,j}$ 是输入数据。
    \item $w_{m,n}^k$ 是第 $k$ 个卷积核的权重。
    \item $b^k$ 是偏置项。
    \item $z_{i,j}^k$ 是卷积结果。
\end{itemize}

\subsubsection{池化层}
池化层用于降维和减少计算量，常用的操作有最大池化和平均池化。例如，对于最大池化：
\[
z_{i,j} = \max_{p,q} x_{i+p,j+q},
\]
其中 $p,q$ 是池化窗口的范围。

\subsubsection{全连接层}
全连接层将前面提取的特征映射到最终的输出空间。其计算公式为：
\[
z = Wx + b,
\]
其中 $W$ 是权重矩阵，$b$ 是偏置项。

\subsection{ResNet: 深度残差网络}

ResNet（Residual Network）\footnote{\url{https://arxiv.org/pdf/1512.03385}}通过引入残差块（Residual Block）解决了深层神经网络的梯度消失和退化问题。其核心思想是学习残差函数 $F(x) := H(x) - x$，其中 $H(x)$ 是目标函数，$x$ 是输入。网络的基本单元为残差块，数学表达如下：

\subsubsection{残差块公式}
\[
y = F(x, \{W_i\}) + x
\]
其中：
\begin{itemize}
    \item $x$ 是输入特征。
    \item $F(x, \{W_i\})$ 是通过卷积、批归一化和激活函数计算得到的残差函数：
    \[
    F(x, \{W_i\}) = \sigma(W_2 \cdot \text{BatchNorm}(\sigma(W_1 \cdot x)))
    \]
    \item $W_1$ 和 $W_2$ 是卷积核权重。
    \item $\sigma(\cdot)$ 是激活函数（通常为 ReLU）。
\end{itemize}

\subsubsection{ResNet 结构}
ResNet 的总体结构可以表达为：
\[
h^{(l+1)} = h^{(l)} + F(h^{(l)}, \{W^{(l)}\})
\]
其中：
\begin{itemize}
    \item $h^{(l)}$ 是第 $l$ 层的特征。
    \item $F(h^{(l)}, \{W^{(l)}\})$ 是第 $l$ 层的残差函数。
\end{itemize}

\subsubsection{网络深度}
ResNet-18、ResNet-34 等通过堆叠多个残差块构建，网络的层数为：
\[
\text{总层数} = 2 \times \text{残差块数} + \text{输入输出层数}
\]

\subsubsection{瓶颈块（Bottleneck Block）}
对于深层网络（如 ResNet-50、ResNet-101），使用瓶颈块减少参数量：
\[
F(x) = W_3 \cdot \sigma(W_2 \cdot \text{BatchNorm}(\sigma(W_1 \cdot x)))
\]
瓶颈块中：
\begin{itemize}
    \item $W_1$: 1x1 卷积，用于降维。
    \item $W_2$: 3x3 卷积，用于特征提取。
    \item $W_3$: 1x1 卷积，用于升维。
\end{itemize}

\subsection{Wide Residual Network (WideResNet)}

Wide Residual Network (WideResNet)\footnote{\url{https://arxiv.org/pdf/1605.07146}} 
是 ResNet 的一种变体，旨在通过增加网络宽度而不是深度来提高模型性能，同时降低训练复杂度。WideResNet 的主要公式如下：

\begin{equation}
x_{l+1} = x_l + \mathcal{F}(x_l, \{W_{l,i}\}),
\end{equation}

其中 $\mathcal{F}$ 表示残差映射（Residual Mapping），
$\{W_{l,i}\}$ 表示第 $l$ 层的可学习参数集合。
WideResNet 通过引入一个宽度因子 $k$ 来增加每层的通道数，
即将 ResNet 的每层特征图数量扩展为 $k$ 倍。

\subsubsection{WideResNet 与 ResNet 的区别}

WideResNet 在设计上主要与 ResNet 有以下区别：
\begin{itemize}
    \item \textbf{宽度 vs. 深度}: ResNet 通过增加网络的深度来增强学习能力，
    但过深的网络可能带来梯度消失或过拟合问题。
    WideResNet 则通过增加每层的通道数（宽度因子 $k$）来提高网络的容量，
    同时避免了过深网络的训练问题。
    \item \textbf{简化的 Bottleneck 结构}: ResNet 在深层通常使用 Bottleneck 
    结构（$1\times1$, $3\times3$, $1\times1$ 的卷积），
    而 WideResNet 直接使用标准卷积层，从而简化了模型。
    \item \textbf{减少深度}: WideResNet 显著降低了模型深度，
    使得训练时间大幅减少。例如，WideResNet-28-10 指的是一个深度为 28，
    宽度因子为 10 的 WideResNet。
\end{itemize}

\subsubsection{CIFAR-10 上使用 WideResNet}
在 WideResNet 的原始论文中，WideResNet-28-10 在 CIFAR-10 数据集上达到了接近最优的性能，
其错误率低至 3.8\%，显著优于传统的 ResNet。

CIFAR-10 数据集是一个由 10 类小图像组成的数据集，每张图像的尺寸为 $32\times32$ 像素。
WideResNet 在 CIFAR-10 上表现出色的原因包括：
\begin{itemize}
    \item \textbf{高效的特征表示}: 对于小尺寸图像，
    增加网络的宽度（而非深度）可以更有效地捕获局部和全局特征，从而提升分类性能。
    \item \textbf{优化效率}: CIFAR-10 数据集的样本较小，
    WideResNet 的浅层网络结构能够显著减少训练时间，同时保持或超越深度网络的准确率。
    \item \textbf{防止过拟合}: 在 CIFAR-10 这样的小型数据集上，
    过深的网络容易过拟合，而 WideResNet 的较浅结构通过宽度扩展减少了这种风险。
\end{itemize}

\subsection{AutoAugmentPolicy 数据增强}

AutoAugment\footnote{\url{http://arxiv.org/pdf/1805.09501}} 
使用概率性数据增强策略提高模型的泛化能力。以下为 CIFAR-10 策略中的数据增强方法和数学描述。

\subsubsection{数据增强方法列表}
\begin{enumerate}
    \item \textbf{Invert}: 将图像颜色取反。
    \[
    I'(x, y) = 255 - I(x, y)
    \]
    其中 $I(x, y)$ 是原始像素值，$I'(x, y)$ 是增强后的像素值。

    \item \textbf{Contrast}: 调整对比度。令图像的平均亮度为 $\mu$，对比度调整公式为：
    \[
    I'(x, y) = \mu + \alpha \cdot (I(x, y) - \mu)
    \]
    其中 $\alpha$ 为增强强度。

    \item \textbf{Rotate}: 图像旋转 $\theta$ 度：
    \[
    \begin{bmatrix}
    x' \\ y'
    \end{bmatrix}
    =
    \begin{bmatrix}
    \cos\theta & -\sin\theta \\
    \sin\theta & \cos\theta
    \end{bmatrix}
    \begin{bmatrix}
    x \\ y
    \end{bmatrix}
    \]

    \item \textbf{TranslateX / TranslateY}: 在水平 / 垂直方向上平移 $\Delta x$ 或 $\Delta y$ 像素：
    \[
    I'(x + \Delta x, y + \Delta y) = I(x, y)
    \]

    \item \textbf{Sharpness}: 调整图像锐化程度，使用卷积核增强边缘信息。

    \item \textbf{ShearX / ShearY}: 图像沿 X / Y 轴剪切：
    \[
    \begin{bmatrix}
    x' \\ y'
    \end{bmatrix}
    =
    \begin{bmatrix}
    1 & \lambda_x \\
    \lambda_y & 1
    \end{bmatrix}
    \begin{bmatrix}
    x \\ y
    \end{bmatrix}
    \]
    其中 $\lambda_x, \lambda_y$ 为剪切强度。

    \item \textbf{AutoContrast}: 自动调整对比度，使像素值覆盖整个动态范围。

    \item \textbf{Equalize}: 直方图均衡化：
    \[
    H'(v) = \left\lfloor \frac{\text{CDF}(v) - \text{CDF}_{\text{min}}}{1 - \text{CDF}_{\text{min}}} \cdot (L - 1) \right\rfloor
    \]
    其中 $\text{CDF}(v)$ 是像素值 $v$ 的累计分布函数。

    \item \textbf{Posterize}: 降低图像的色深：
    \[
    I'(x, y) = \lfloor \frac{I(x, y)}{2^b} \rfloor \cdot 2^b
    \]
    其中 $b$ 为剩余位数。

    \item \textbf{Color}: 调整颜色饱和度。

    \item \textbf{Brightness}: 调整亮度：
    \[
    I'(x, y) = I(x, y) + \beta
    \]

    \item \textbf{Solarize}: 反转高于某阈值 $T$ 的像素值：
    \[
    I'(x, y) = 
    \begin{cases} 
    I(x, y) & \text{if } I(x, y) < T \\
    255 - I(x, y) & \text{if } I(x, y) \geq T
    \end{cases}
    \]
\end{enumerate}

\section{实验步骤与结果分析}
\subsection{在cifar10上用PyTorch训练两层神经网络分类器}
训练流程为，定义超参数、神经网络，读取数据集，划分数据集为训练集与验证集，实例化模型、优化器、损失函数，
开始训练，在验证集上验证模型性能，保存模型，具体代码如下：
\begin{pythoncode}
import time
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.utils.tensorboard.writer import SummaryWriter

# Tensorbaord日志
path_log = Path(f"./logs/{time.strftime('%Y%m%d-%H%M%S')}")
writer = SummaryWriter(path_log)

# 超参数设置
batch_size = 64
learning_rate = 0.001
num_epochs = 20
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# 数据加载和预处理
transform = transforms.Compose([
  transforms.ToTensor(),        # 转换为 Tensor
  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化到 [-1, 1]
])

train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 定义全连接神经网络
class FullyConnectedNN(nn.Module):
  def __init__(self, input_size, hidden_size, num_classes):
    super(FullyConnectedNN, self).__init__()
    self.fc1 = nn.Linear(input_size, hidden_size)  # 输入到隐藏层
    self.relu = nn.ReLU()             # 激活函数
    self.fc2 = nn.Linear(hidden_size, num_classes)  # 隐藏层到输出层

  def forward(self, x):
    x = x.view(x.size(0), -1)  # 展平
    x = self.fc1(x)
    x = self.relu(x)
    x = self.fc2(x)
    return x

# 模型实例化
input_size = 32 * 32 * 3  # CIFAR-10 图像大小 (32x32x3)
hidden_size = 256     # 隐藏层神经元数
num_classes = 10      # CIFAR-10 分类数
model = FullyConnectedNN(input_size, hidden_size, num_classes).to(device)

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
global_step = 0
best_eval_acc = 0

# 训练模型
for epoch in range(num_epochs):
  model.train()
  for batch_idx, (data, target) in enumerate(train_loader):
    data, target = data.to(device), target.to(device)
    # 前向传播
    outputs = model(data)
    loss = criterion(outputs, target)
    _, predicted = torch.max(outputs, 1)
    acc = (target == predicted).sum().item() / batch_size

    # 反向传播
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    global_step += 1
      
    if (batch_idx + 1) % 100 == 0:
      writer.add_scalar("chart/loss", loss.item(), global_step)
      writer.add_scalar("chart/train_acc", acc, global_step)
      print(f"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, Acc: {acc:.4f}")

  # 测试模型
  model.eval()
  correct = 0
  total = 0
  with torch.no_grad():
    for data, target in test_loader:
      data, target = data.to(device), target.to(device)
      outputs = model(data)
      _, predicted = torch.max(outputs.data, 1)
      total += target.size(0)
      correct += (predicted == target).sum().item()

  eval_acc = correct / total
  print(f"Test Accuracy: {100 * eval_acc:.2f}%")
  writer.add_scalar("chart/eval_acc", eval_acc, global_step)

  if eval_acc > best_eval_acc:
    best_eval_acc = eval_acc
    # 保存最优eval模型
    path_save_model = f"cifar10_fc_model_best_eval.pth"
    torch.save(model.state_dict(), path_log / path_save_model)
    print(f"Best eval model ({100*eval_acc:.2f}%) saved as {path_log / path_save_model}")
    

# 保存模型
path_save_model = f"cifar10_fc_model_{global_step}.pth"
torch.save(model.state_dict(), path_log / path_save_model)
print(f"Last model saved as {path_log / path_save_model}")
print(f"Best eval accuracy {100 * best_eval_acc:.2f}%")
\end{pythoncode}
TensorBoard日志图片如下：
\begin{figure}[H]
  \centering
  \subfigure[损失函数图像]{\includegraphics[width=0.32\textwidth]{../code/figures/1_loss.png}}
  \subfigure[训练中准确率图像]{\includegraphics[width=0.32\textwidth]{../code/figures/1_train_acc.png}}
  \subfigure[训练中准确率图像]{\includegraphics[width=0.32\textwidth]{../code/figures/1_eval_acc.png}}
  \setlength{\abovecaptionskip}{0ex}  % 如果使用了minted会增大图像与标题间距需要进行缩小
  \caption{训练20个epochs的TensorBoard日志图像，在验证集上的最优准确率为第11个epoch时的52.54\%}
  \label{fig-1}
\end{figure}
\subsection{在cifar10上用PyTorch训练卷积网络分类器}
与全连接神经网络不同之处在于：
\begin{enumerate}
    \item 使用了图像增强，包括随机裁剪，随机水平翻转，色彩抖动；
    \item 三个CNN卷积块（2D卷积，批归一化，Mish激活函数），每个卷积块后经过一个最大池化将图像缩小一倍，
    最后展平，用全连接做输出头预测类别。
\end{enumerate}
\begin{pythoncode}
import time
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.utils.tensorboard.writer import SummaryWriter

# Tensorbaord日志
path_log = Path(f"./logs/{time.strftime('%Y%m%d-%H%M%S')}")
writer = SummaryWriter(path_log)

# 检查是否有可用 GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 超参数设置
batch_size = 64
learning_rate = 0.001
num_epochs = 20

# 数据增强和预处理
transform_train = transforms.Compose([
  transforms.RandomCrop(32, padding=4),      # 随机裁剪
  transforms.RandomHorizontalFlip(),      # 随机水平翻转
  transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # 色彩抖动
  transforms.ToTensor(),
  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化
])

transform_test = transforms.Compose([
  transforms.ToTensor(),
  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform_train, download=True)
test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform_test, download=True)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

class CNN(nn.Module):
  def __init__(self, in_ch, out_ch, kernel, stride, padding):
    super().__init__()
    self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel, stride=stride, padding=padding)
    self.bn = nn.BatchNorm2d(out_ch)
    self.mish = nn.Mish()
  
  def forward(self, x):
    return self.mish(self.bn(self.conv(x)))

# 定义 CNN 模型
class Model(nn.Module):
  def __init__(self, num_classes=10):
    super().__init__()
    self.backbone = nn.Sequential(
      CNN(3, 64, 3, 1, 1),
      nn.MaxPool2d(kernel_size=2, stride=2),
      CNN(64, 128, 3, 1, 1),
      nn.MaxPool2d(kernel_size=2, stride=2),
      CNN(128, 256, 3, 1, 1),
      nn.MaxPool2d(kernel_size=2, stride=2),
    )
    self.head = nn.Sequential(
      nn.Linear(256 * 4 * 4, 512),
      nn.Mish(),
      nn.Linear(512, num_classes),
    )

  def forward(self, x):
    x = self.backbone(x)
    x = nn.Flatten()(x)
    x = self.head(x)
    return x

# 初始化模型、损失函数和优化器
model = Model().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
global_step = 0
best_eval_acc = 0

# 训练模型
for epoch in range(num_epochs):
  model.train()
  for batch_idx, (data, target) in enumerate(train_loader):
    data, target = data.to(device), target.to(device)

    # 前向传播
    outputs = model(data)
    loss = criterion(outputs, target)
    _, predicted = torch.max(outputs, 1)
    acc = (target == predicted).sum().item() / batch_size

    # 反向传播
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    global_step += 1

    if (batch_idx + 1) % 100 == 0:
      writer.add_scalar("chart/loss", loss.item(), global_step)
      writer.add_scalar("chart/train_acc", acc, global_step)
      print(f"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, Acc: {acc:.4f}")

  # 测试模型
  model.eval()
  correct = 0
  total = 0
  with torch.no_grad():
    for data, target in test_loader:
      data, target = data.to(device), target.to(device)
      outputs = model(data)
      _, predicted = torch.max(outputs.data, 1)
      total += target.size(0)
      correct += (predicted == target).sum().item()

  eval_acc = correct / total
  print(f"Test Accuracy: {100 * eval_acc:.2f}%")
  writer.add_scalar("chart/eval_acc", eval_acc, global_step)

  if eval_acc > best_eval_acc:
    best_eval_acc = eval_acc
    # 保存最优eval模型
    path_save_model = f"cifar10_fc_model_best_eval.pth"
    torch.save(model.state_dict(), path_log / path_save_model)
    print(f"Best eval model ({100*eval_acc:.2f}%) saved as {path_log / path_save_model}")

# 保存模型
path_save_model = f"cifar10_fc_model_{global_step}.pth"
torch.save(model.state_dict(), path_log / path_save_model)
print(f"Last model saved as {path_log / path_save_model}")
print(f"Best eval accuracy {100 * best_eval_acc:.2f}%")
\end{pythoncode}
TensorBoard日志图片如下：
\begin{figure}[H]
  \centering
  \subfigure[损失函数图像]{\includegraphics[width=0.32\textwidth]{../code/figures/2_loss.png}}
  \subfigure[训练中准确率图像]{\includegraphics[width=0.32\textwidth]{../code/figures/2_train_acc.png}}
  \subfigure[训练中准确率图像]{\includegraphics[width=0.32\textwidth]{../code/figures/2_eval_acc.png}}
  \setlength{\abovecaptionskip}{0ex}  % 如果使用了minted会增大图像与标题间距需要进行缩小
  \caption{训练20个epochs的TensorBoard日志图像，在验证集上的最优准确率为第19个epoch时的84.48\%}
  \label{fig-1}
\end{figure}

\subsection{在cifar10上用WideResNet+AutoAugment训练}
这一次，我参考了GitHub上\href{https://github.com/4uiiurz1/pytorch-auto-augment/tree/master}{pytorch-auto-augment}仓库的代码，
使用了WideResNet和AutoAugment进行训练，并加了L2范数正则项，和余弦学习率调整，训练120个epoch，在验证集上最好能达到96.44\%的准确率。

首先演示Augment数据增强效果图：
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{../code/figures/grid_augment.png}
  \caption{训练集上不同图片增强后的效果}
\end{figure}

演示验证集上单张图片随机增强后的效果图：
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{../code/figures/single_augment.png}
  \caption{验证集上同一张图片增强后的效果，左上角为原始图片}
\end{figure}

代码非常简单，可以直接使用如下代码构建图像变换函数，从而作用在数据集上，最后用matplotlib可视化变换效果即可：
\begin{pythoncode}
from torchvision.transforms.autoaugment import AutoAugment, AutoAugmentPolicy

transform = AutoAugment(AutoAugmentPolicy.CIFAR10)  # 创建变换

# 作用于数据集上
train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)  

def grid_augment():
  train_iter = iter(train_dataset)
  r = 6
  c = 10
  figure, axs = plt.subplots(r, c, figsize=(10, 6))

  for i in range(r):
    for j in range(c):
      img = next(train_iter)[0]
      ax: Axes = axs[i,j]
      ax.set_axis_off()
      ax.imshow(img)
  plt.tight_layout()
  plt.savefig(path_figures / "grid_augment.png", dpi=100)
  plt.show()
\end{pythoncode}

学会数据增强后，类似之前训练模型的方法，只需简单修改即可得到训练代码：
\begin{pythoncode}
import time
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.utils.tensorboard.writer import SummaryWriter
from torchvision.transforms.autoaugment import AutoAugment, AutoAugmentPolicy
from wide_resnet import WideResNet

# Tensorbaord日志
path_log = Path(f"./logs/{time.strftime('%Y%m%d-%H%M%S')}-wide-resnet")
writer = SummaryWriter(path_log)

# 检查是否有可用 GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 超参数设置
batch_size = 128
learning_rate = 0.1
momentum = 0.9
weight_decay = 1e-4
num_epochs = 120
autoaugment = True

# 数据增强和预处理
transform_train = transforms.Compose([
  transforms.RandomCrop(32, padding=4),
  transforms.RandomHorizontalFlip(),
  *([AutoAugment(AutoAugmentPolicy.CIFAR10)] if autoaugment else []),
  transforms.ToTensor(),
  transforms.Normalize((0.4914, 0.4822, 0.4465),
                      (0.2023, 0.1994, 0.2010)),
])

transform_test = transforms.Compose([
  transforms.ToTensor(),
  transforms.Normalize((0.5071, 0.4867, 0.4408),
                       (0.2675, 0.2565, 0.2761)),
])

train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform_train, download=True)
test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform_test, download=True)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)

# 初始化模型、损失函数和优化器
model = WideResNet(depth=28, width=10, num_classes=10).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * num_epochs)
# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [60, 120, 160], 0.2)
global_step = 0
best_eval_acc = 0

# 训练模型
for epoch in range(num_epochs):
  model.train()
  for batch_idx, (data, target) in enumerate(train_loader):
    data, target = data.to(device), target.to(device)

    # 前向传播
    outputs = model(data)
    loss = criterion(outputs, target)
    _, predicted = torch.max(outputs, 1)
    acc = (target == predicted).sum().item() / batch_size

    # 反向传播
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    scheduler.step()
    global_step += 1

    if (batch_idx + 1) % 100 == 0:
      writer.add_scalar("chart/loss", loss.item(), global_step)
      writer.add_scalar("chart/train_acc", acc, global_step)
      writer.add_scalar("chart/learning_rate", scheduler.get_last_lr()[0], global_step)
      print(f"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}, Acc: {acc:.4f}")

  # scheduler.step()

  # 测试模型
  model.eval()
  correct = 0
  total = 0
  with torch.no_grad():
    for data, target in test_loader:
      data, target = data.to(device), target.to(device)
      outputs = model(data)
      _, predicted = torch.max(outputs.data, 1)
      total += target.size(0)
      correct += (predicted == target).sum().item()

  eval_acc = correct / total
  print(f"Test Accuracy: {100 * eval_acc:.2f}%")
  writer.add_scalar("chart/eval_acc", eval_acc, global_step)

  if eval_acc > best_eval_acc:
    best_eval_acc = eval_acc
    # 保存最优eval模型
    path_save_model = f"cifar10_wide_resnet_model_best_eval.pth"
    torch.save(model.state_dict(), path_log / path_save_model)
    print(f"Best eval model ({100*eval_acc:.2f}%) saved as {path_log / path_save_model}")

# 保存模型
path_save_model = f"cifar10_wide_resnet_model_{global_step}.pth"
torch.save(model.state_dict(), path_log / path_save_model)
print(f"Last model saved as {path_log / path_save_model}")
print(f"Best eval accuracy {100 * best_eval_acc:.2f}%")
\end{pythoncode}
TensorBoard日志图片如下
\begin{figure}[H]
  \centering
  \subfigure[损失函数图像]{\includegraphics[width=0.32\textwidth]{../code/figures/3_loss.png}}
  \subfigure[训练中准确率图像]{\includegraphics[width=0.32\textwidth]{../code/figures/3_train_acc.png}}
  \subfigure[训练中准确率图像]{\includegraphics[width=0.32\textwidth]{../code/figures/3_eval_acc.png}}
  \setlength{\abovecaptionskip}{0ex}  % 如果使用了minted会增大图像与标题间距需要进行缩小
  \caption{训练120个epochs的TensorBoard日志图像，在验证集上的最优准确率为第116个epoch时的96.44\%}
  \label{fig-1}
\end{figure}\vspace{-2ex}

\section{总结}
\begin{table}[!h]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{PyTorch在CIFAR10数据集上模型性能对比表} \label{tabel-yolo} \vspace{2mm}
  \begin{tabularx}{\textwidth} {
   >{\centering\arraybackslash}X 
   >{\centering\arraybackslash}X
   >{\centering\arraybackslash}X
   >{\centering\arraybackslash}X
   >{\centering\arraybackslash}X
   >{\centering\arraybackslash}X
   >{\centering\arraybackslash}X
   >{\centering\arraybackslash}X
  }
  % \toprule[1.5pt]
  \hline
  网络模型&学习率调整&L2正则&数据增强&总epoch&验证集最优epoch&验证集最优准确率&训练集最优准确率\\
  \hline
  % \midrule[1pt]
  两层全连接&无&无&无&20&11&52.54\%&85.94\%\\
  3层卷积网络&无&无&裁剪、水平翻转、色彩抖动&20&19&84.48\%&93.75\%\\
  WidResNet&两段变换&$10^{-4}$&无&120&71&94.91\%&100\%\\
  WidResNet&Cosine&$10^{-4}$&无&120&115&94.86\%&100\%\\
  WidResNet&Cosine&$10^{-4}$&Auto-Augment&120&116&\textbf{96.44\%}&99.22\%\\
  \hline
  % \bottomrule[1.5pt]
  \end{tabularx}
\end{table}

代码使用说明，上述三个报告分别对应代码\pythoninline{1_relu.py}，\pythoninline{2_mish.py}，\pythoninline{3_wide_resnet.py}，
直接执行代码即可开始训练，TensorBaord查看方式：\add
\begin{pythoncode}
# 安装tensorboard
pip install tensorboard
# 进入终端执行
tensorboard --logdir ./logs
\end{pythoncode}

\paragraph{软件说明}
使用的Python版本为3.11（任何3.8以上版本均可），
PyTorch版本为2.5.1-cuda（任何PyTorch版本均可）。

\paragraph{硬件说明}使用的CPU为AMD 5700X，显卡为RTX-4080，
训练上述三个模型分别用时1m27s，5m23s，2h11m58s。

\end{document}
